<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <title>On the Convergence of Conjugate Gradient Variants in Finite Precision Arithmetic</title>
  <meta name="description" content="Multiple mathematically equivalent variants of the Conjugate Gradient algorithm have been developed to reduce communication in high performance environments. We analyze these variants in the context of [Greenbaum 89].">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
  <meta name="author" content="Tyler Chen" />

  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link href="../../tc.ico" rel="shortcut icon" >
  <link href="../../css/main.css" rel="stylesheet" type="text/css" media="screen" />
  <link href="../../css/print.css" rel="stylesheet" type="text/css" media="print"/>
  <link rel="stylesheet" href="../../font/lato/stylesheet.css" type="text/css" charset="utf-8" />
  <link rel="stylesheet" href="../../font/vollkorn/stylesheet.css" type="text/css" charset="utf-8" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-50592837-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-50592837-1');
</script>

</head>
<body>
<div id="contentContainer">
<h1>On the Convergence of Conjugate Gradient Variants in Finite Precision Arithmetic</h1>
<p class="author"><a href="https://chen.pw">Tyler Chen</a></p>
<p>This is a companion piece to the publication:</p>
<p><pre>@article{cg_variants_convergence_rates,
    doi = {10.1137/20m1346249},
    year = {2021},
    month = jul,
    publisher = {Society for Industrial {\&} Applied Mathematics (SIAM)},
    pages = {S496--S515},
    author = {Anne Greenbaum and Hexuan Liu and Tyler Chen},
    title = {On the Convergence Rate of Variants of the Conjugate Gradient Algorithm in Finite Precision Arithmetic},
    journal = {SIAM Journal on Scientific Computing},
    eprint = {1905.05874},
    archivePrefix = {arXiv},
    primaryClass = {cs.NA},
}</pre></p>
<p>If you are not familiar with the Conjugate Gradient method, it may be worth reading through my introduction <a href="../cg/index.html">here</a>.</p>
<p>The behaviour of the conjugate gradient algorithm in <a href="../cg/finite_precision_cg.html">finite precision</a> is very different than what is predicted by exact arithmetic theory.
In this sense, the algorithm could be considered unstable.
However, the conjugate gradient algorithm is widely used in practice, so it is important to understand its behaviour in finite precision.</p>
<p>One effect is that in finite precision the “rate of convergence” (how many iterations it takes to reach a given level of accuracy) is reduced compared to exact arithmetic.
Previously Anne Greenbaum showed that a “good” implementation of the CG algorithm, when run in finite precision, will behave like exact CG applied to a larger matrix, and that this larger matrix has eigenvalues very near to those of the original matrix.
I’ve written more about this result <a href="../cg/finite_precision_cg.html">here</a>.
A natural question is whether any of the high performance variants satisfy the conditions for Greenbaum’s analysis to apply.
Specifically, the analysis requires that (i) the three term Lanczos recurrence close to satisfied, and (ii) that successive residual vectors are nearly orthogonal.
Unfortunately, nobody has been able to prove this for any of the high performance variants, or even the standard implementation.</p>
<p>In this paper we show (numerically) why on some problems certain variants of the conjugate gradient algorithm converge more slowly than others, but on some problems all variants behave the same.
To do this we first analyze how closely different variants satisfy the three term Lanczos recurrence.
It turns out that the standard implementation, and one due to Chronopoulos and Gear satisfy the three term recurrence to within local rounding errors.
However, the pipelined variant due to Ghysels and Vanroose, which is more parallel, has a larger deviation from a three term recurrence.
While the paper does not prove that this leads to worse convergence, it does provide some intuition for why the rates of convergence observed differ on some problems.</p>
<p class="footer">
The rest of my publications can be found <a href="./../">here</a>.
</p>
</div>
</body>
</html>
