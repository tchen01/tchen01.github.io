<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <title>Low-memory Krylov subspace methods for optimal rational matrix function approximation</title>
  <meta name="description" content="We introduce low-memory Krylov subspace methods for approximation rational matrix functions applied to a vector">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
  <meta name="author" content="Tyler Chen" />

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link href="../../tc.ico" rel="shortcut icon" >
  <link href="../../css/main.css" rel="stylesheet" type="text/css" media="screen" />
  <link href="../../css/print.css" rel="stylesheet" type="text/css" media="print"/>
  <link rel="stylesheet" href="../../font/lato/stylesheet.css" type="text/css" charset="utf-8" />
  <link rel="stylesheet" href="../../font/vollkorn/stylesheet.css" type="text/css" charset="utf-8" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-50592837-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-50592837-1');
</script>

</head>
<body>
<div id="contentContainer">
<h1>Low-memory Krylov subspace methods for optimal rational matrix function approximation</h1>
<p class="author"><a href="https://chen.pw">Tyler Chen</a></p>
<p>This is a companion piece to the publication:</p>
<p><pre>@misc{lowmem_rational_opt,
    title={Low-memory Krylov subspace methods for optimal rational matrix function approximation},
    author={Tyler Chen and Anne Greenbaum and Cameron Musco and Christopher Musco},
    year={2022},
    eprint={2202.11251},
    archivePrefix={arXiv},
    primaryClass={math.NA},
}</pre></p>
<p><a href="./lanczos_function_CIF.html">Matrix functions</a> have a myriad of applications in nearly every field of computational science.
Among the most powerful algorithms for computing the product of a matrix function <span class="math inline">\(f[\mathbf{A}]\)</span> with a vector <span class="math inline">\(\mathbf{b}\)</span> are Krylov subspace methods such as the Lanczos method for matrix function approximation (Lanczos-FA).
These algorithms access <span class="math inline">\(\mathbf{A}\)</span> only through matrix products <span class="math inline">\(\mathbf{v} \mapsto \mathbf{A}\mathbf{v}\)</span>, and are therefore well suited for situations in which <span class="math inline">\(\mathbf{A}\)</span> is too large to store in fast memory.
However, for general matrix functions, the amount of storage required often grows linearly with the number of iterations, resulting in a computational bottleneck.</p>
<p>One notable function is <span class="math inline">\(f(x) = 1/x\)</span> in which case <span class="math inline">\(f[\mathbf{A}]\mathbf{b} = \mathbb{A}^{-1} \mathbf{b}\)</span> corresponds to the solution of the linear system of equations <span class="math inline">\(\mathbf{A} \mathbf{x} = \mathbf{b}\)</span>.
In this case, algorithms such as the conjugate gradient algorithm and the minimum residual algorithm can approximate <span class="math inline">\(\mathbf{A}^{-1} \mathbf{b}\)</span> using an amount of storage <em>independent</em> of the number of iterations taken.
Moreover, these algorithms produce iterates which are <em>optimal</em> over Kylrov subspace, thereby guaranteeing fast convergence on matrices with spectrums which have nice properties like outlaying or clustered eigenvalues.</p>
<p>In this paper, we first describe a mathematical algorithms which outputs the optimal approximation to an arbitrary rational matrix function.
Here optimal is with respect to a certain norm which depends on the rational function in question.
We then give low-memory implementations of our optimal algorithm and of Lanczos-FA which do not require more storage as more iterations are run.
Finally, we use this optimal approximation to derive (non-optimal) approximations to other matrix functions such the matrix-sign function.
Both the conjugate gradient algorithm and the minimum residual algorithms are obtained as special cases of our optimal approximation, so this paper also provides some insights into the relationship between the algorithms.</p>
<p class="footer">
The rest of my publications can be found <a href="./../">here</a>.
</p>
</div>
</body>
</html>
