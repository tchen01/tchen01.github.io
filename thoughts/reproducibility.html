<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Tyler Chen</title>
<meta name="description" content="I'm Tyler Chen, applied math PhD student at the University of Washington. Find out more about my research, teaching, and educational beliefs, and then get in contact with me.">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width user-scalable=no">

<link href="../tc.ico" rel="shortcut icon" >
<link href="../css/main.css" rel="stylesheet" type="text/css" media="screen" />
<link href="../css/print.css" rel="stylesheet" type="text/css" media="print"/>
<link rel="stylesheet" href="../font/lato/stylesheet.css" type="text/css" charset="utf-8" />

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-50592837-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-50592837-1');
</script>
</head>

<body>
<div id="contentContainer">
    <h1>Reproducibility, Inclusivity, and Open Science</h1>
	<p>This is still a rough draft</p>

    <p>Science is built on the idea that if two people run the same experiment, they should get the same results. 

There are many fields where it is very easy for researchers to make the costs (time, money, etc) of reproducing their experiments low. I believe, that in these cases, it is important that scientists make a good faith effort to do so, and to do so in a way which is inclusive of the broader scientific community.</p> 
    <p>I'll discuss the issue in the context of computational science, but most of what I'm saying applies to other fields as well.</p>
        
    <p>A lot of papers relating to my research go something like this: "(~ task ~) is important for (~ grant keywords ~) reasons. Recently, because of (~ big data ~), there has been interest in fast algorithms for (~ task ~). Other papers have tried using (~ some method ~) quickly, however there are limitations with (~ some method ~). We propose an alternative to (~ some method ~) to address the limitations of (~ past paper ~)". A mathematical description of the new algorithm is presented, and then generally some numerical experiments which demonstrate that the new method works, and is possibly better than the old methods are included.</p>
    <p>Often, in order to understand the paper better, I will try to replicate the results of the paper. Based on the theoretical description algorithm, I can implement it myself and try to reproduce their results. However, in practice, a lot of pieces of the algorithm may be dependent on the exact setup of the machine the code is run on. For example, if the original authors used BLACKBOX™ to write their code, including built in functions for lower level tasks such as matrix multiplication, there is almost no chance that I will end up with an identical implementation.</p>

    <h3>So, what's the problem?</h3>
    <p>The results of the paper are technically reproducible. If I run the exact code the authors used on the right version of BLACKBOX™ I will get the same output. However, even assuming that the authors posted their code for others to verify (which is relatively uncommon), there are still reproducibility issues. First, there is no way of knowing the exact algorithms used in the BLACKBOX™ builtin functions. Second, since BLACKBOX™ is needed to reproduce the experiment, only those with access to BLACKBOX™ are able to take part in the verification process. This immediately excludes entire demographics who may not be able to justify the purchase of BLACKBOX™; i.e. high school students (especially those from low income areas), people in developing countries, hobbyists and amateur scientists, etc.</p>
    <p>The first issue has been discussed many times (see any MATLAB vs. Python argument thread). Generally, paid software such as MATLAB and Mathematica are well tested, and for the most part have well implemented algorithms. Even so, trust is required since nobody outside of those companies has access to their source code. In my opinion, using this type of software is only detrimental to the scientific process, especially given that there are a wide range of open source alternatives.</p>  
    <p>The second issue is less talked about, and extends far beyond reproducibility. While there are many cases where using proprietary software may be unavoidable, there are a huge number of cases where these programs are used only because of familiarity or personal comfort. The fact that many research institutions provide free access to paid software only perpetrates the problem, since researchers can easily forget that not everyone has the same level of access to these programs as they do. This has the effect of excluding less privileged persons from the scientific process and furthering academia's (well deserved) reputation as an "ivory tower" inaccessible to those without sufficient resources.</p>
	
	<h3>Why should academics in stem care?</h3>
	<p>It's reasonable to ask is why should researchers care about any of this.</p>
	<p>Many institutions, including R1 research schools, do not provide licences for programs such as MATLAB. This means that students (and faculty) are frequently placed in the position of having to purchase software on their own in order to test the results of papers or work with collaborators. This has a disproportionate effect on people from lower income backgrounds, especially in the case of grad students and non-tenure track faculty. Using open source software can help take this burden off of your peers.</p>
	<p>It's not uncommon that people outside academia may want to use the code from research papers. For instance the findings of this <a href="https://arxiv.org/pdf/1508.06576.pdf">paper</a>, which outlined how to render an input image in the style of famous painters, have been widely used by hobbyists and non academics. There are now multiple subreddits and youtube channels devoted specifically to computer generated art, all helping bring new advancements in science to the mainstream. Public interests in an area can drive funding, and inspire new students to join the field.</p>
    
	<h3>What can we do?</h3>
    <p>When possible use open source alternatives; i.e. Python (with Numpy and Scipy) or Julia instead of MATLAB, Sympy instead of Mathematica, etc. The more people using these softwares, the better they become.</p>
    <p>Read <a href="http://lorenabarba.com/blog/barbagroup-reproducibility-syllabus/">Lorena Barba's</a> website. It has many good resources regarding good technical practices for reproducibility. One key takeaway is to "provide public access to scripts, runs, and results".</p>
    <p>Write code which is understandable by others. Writing well documented code with a broader audience in mind, makes it easier for your research to reach a wide range of people.</p>
	
    <p class="footer">More writing about my opinions on academia can be found <a href="./">here</a>.</p>
</div>
</body>

</html>
